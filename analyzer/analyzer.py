from .audio_io import download_youtube_audio, separate_vocals_demucs, load_audio
from .pitch_extract import estimate_pitch_librosa, estimate_pitch_torchcrepe
from .features import summarize_pitch, summarize_energy
from .utils import midi_to_note


import numpy as np
import librosa
from librosa import display as lrdisplay
import torch
import torchcrepe

# =========================
# ì•ˆì •í™”ìš© ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°
# =========================
FMIN_BASE = 80.0             # 1íŒ¨ìŠ¤ í•˜í•œ(E2)
FMAX_BASE = 1400.0           # 1íŒ¨ìŠ¤ ìƒí•œ(ì—¬ì„± ê³ ìŒ+ê°€ì„± ì¼ë¶€, ìƒí–¥)
FMIN_HIGH = 600.0            # 2íŒ¨ìŠ¤(ê³ ìŒ êµ¬ì¡°) í•˜í•œ
FMAX_HIGH = 1900.0           # 2íŒ¨ìŠ¤(ê³ ìŒ êµ¬ì¡°) ìƒí•œ(ê³ ìŒ ê³¡ ëŒ€ì‘)
VOICING_THRESHOLD = 0.10     # periodicity(0~1) > 0.10 ë§Œ ìœ ì„±
RMS_REL_THRESHOLD = 0.01      # í”„ë ˆì„ RMS > max(RMS)*2% ë§Œ ìœ ì„±
MEDIAN_FILTER_WIN = 5         # CREPE ì „ìš© median ìœˆë„ìš°(í™€ìˆ˜ ê¶Œì¥: 3/5)
MIN_SEG_DURATION_S = 0.10     # 0.1ì´ˆ ë¯¸ë§Œ ìœ ì„± ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
HOP_LENGTH_DEFAULT = 256

# =========================
# ìœ í‹¸
# =========================
def compute_rms(y, sr, hop_length=HOP_LENGTH_DEFAULT):
    print("[4/5] RMS ì—ë„ˆì§€ ì¶”ì¶œ ì¤‘â€¦", flush=True)
    rms = librosa.feature.rms(y=y, hop_length=hop_length)[0]
    times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
    return rms, times

def _remove_short_segments(f0, sr, hop_length, min_duration_s=MIN_SEG_DURATION_S):
    """ì§€ì†ì‹œê°„ì´ ì§§ì€(ì˜ˆ: 0.3s ì´í•˜) ìœ ì„± êµ¬ê°„ì„ NaNìœ¼ë¡œ ì •ë¦¬"""
    frame_time = hop_length / sr
    min_len = int(min_duration_s / frame_time)
    if min_len <= 1:
        return f0

    f0_filtered = f0.copy()
    is_voiced = ~np.isnan(f0_filtered)

    start = None
    for i, voiced in enumerate(is_voiced):
        if voiced and start is None:
            start = i
        elif (not voiced or i == len(is_voiced) - 1) and start is not None:
            end = i if not voiced else i + 1
            seg_len = end - start
            if seg_len < min_len:
                f0_filtered[start:end] = np.nan
            start = None
    return f0_filtered

def _interp_fill_nan(x: np.ndarray) -> np.ndarray:
    """NaNì„ ì–‘ ë ë³´ê°„ìœ¼ë¡œ ì„ì‹œ ì±„ì›€(í•„í„° ì ìš©ì„ ìœ„í•œ ë³´ì¡°), ì´í›„ ì›ë˜ NaNì€ ë³µêµ¬"""
    y = x.copy()
    n = len(y)
    idx = np.arange(n)
    m = ~np.isnan(y)
    if not m.any():
        return x
    y[~m] = np.interp(idx[~m], idx[m], y[m])
    return y

def _median_filter_crepe(f0_hz: np.ndarray, win: int) -> np.ndarray:
    """CREPE ì „ìš© median í•„í„°(í† ì¹˜ ì—°ì‚°). NaNì€ ë³´ê°„ í›„ í•„í„°â†’ì›ë³µ."""
    if win is None or win < 3 or (win % 2 == 0):
        return f0_hz
    mask_voiced = ~np.isnan(f0_hz)
    if not mask_voiced.any():
        return f0_hz
    f0_fill = _interp_fill_nan(f0_hz)
    t = torch.from_numpy(f0_fill).float().unsqueeze(0)  # [1, T]
    with torch.no_grad():
        t_filt = torchcrepe.filter.median(t, win)
    f0_filt = t_filt.squeeze(0).cpu().numpy()
    f0_filt[~mask_voiced] = np.nan
    return f0_filt

# =========================
# ì˜¥íƒ€ë¸Œ ë³´ì •(ê²€ì‚°) í•„í„°
# =========================
def _fix_octave_jump(f0: np.ndarray, strength: float = 0.6) -> np.ndarray:
    """
    ì˜¥íƒ€ë¸Œ í•˜í–¥/ìƒí–¥ í˜¼ë™ ë³´ì •.
    - ì „ì—­ ì¤‘ì•™ê°’ ê¸°ì¤€ìœ¼ë¡œ 0.6ë°° ì´ìƒ ë²—ì–´ë‚œ í”„ë ˆì„ì— ëŒ€í•´ 2ë°°/1/2 í›„ë³´ë¥¼ í…ŒìŠ¤íŠ¸
    - êµ­ë¶€(ìœˆë„ìš°) ì¤‘ì•™ê°’ìœ¼ë¡œë„ ì¬ê²€ì‚°
    """
    out = f0.copy()
    voiced = ~np.isnan(out)
    if voiced.sum() < 10:
        return out

    med = np.nanmedian(out)
    if med <= 0:
        return out

    # í›„ë³´ ìƒì„±
    cand_hi = out * 2.0
    cand_lo = out / 2.0

    # ì „ì—­ ê¸°ì¤€
    dev = np.abs(out - med)
    far = dev > (med * strength)

    # êµ­ë¶€ ê¸°ì¤€(Â±0.25s)
    idx = np.arange(len(out))
    # hop_lengthëŠ” ìƒìœ„ì—ì„œë§Œ ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°„ë‹¨ êµ­ë¶€ ì°½ í¬ê¸°(7í”„ë ˆì„) ì‚¬ìš©
    win = 7
    local_med = out.copy()
    for i in range(len(out)):
        a = max(0, i - win // 2)
        b = min(len(out), i + win // 2 + 1)
        local_med[i] = np.nanmedian(out[a:b]) if np.any(voiced[a:b]) else med

    # ê±°ë¦¬ ë¹„êµ(ì „ì—­/êµ­ë¶€ ëª¨ë‘ì—ì„œ ë” ê°€ê¹Œìš´ í›„ë³´ë¡œ êµì²´)
    def closer(x, y, target):
        return np.abs(x - target) < np.abs(y - target)

    choose_hi = closer(cand_hi, out, med) & closer(cand_hi, out, local_med)
    choose_lo = closer(cand_lo, out, med) & closer(cand_lo, out, local_med)

    out[far & choose_hi] = cand_hi[far & choose_hi]
    out[far & choose_lo] = cand_lo[far & choose_lo]
    return out

# =========================
# CREPE ì˜ˆì¸¡ (ë‹¨ì¼ íŒ¨ìŠ¤)
# =========================
def _predict_crepe_once(y, sr, hop_length, fmin, fmax, device):
    """
    ë‹¨ì¼ íŒ¨ìŠ¤ CREPE + periodicity/RMS ë§ˆìŠ¤í¬ + median í•„í„° + ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
    """
    if y.ndim > 1:
        y = librosa.to_mono(y)
    audio = torch.tensor(y, dtype=torch.float32, device=device).unsqueeze(0)  # [1, T]

    with torch.no_grad():
        f0, per = torchcrepe.predict(
            audio=audio,
            sample_rate=sr,          # âœ… ìµœì‹  torchcrepe ì¸ìëª…
            hop_length=hop_length,
            fmin=fmin,
            fmax=fmax,
            model='full',
            batch_size=512,
            device=device,
            return_periodicity=True
        )  # [1, T]

    f0 = f0.squeeze(0).cpu().numpy()
    per = per.squeeze(0).cpu().numpy()

    # periodicity / RMS ë§ˆìŠ¤í¬
    mask_per = per > VOICING_THRESHOLD
    rms = librosa.feature.rms(y=y, hop_length=hop_length)[0]
    rms_max = float(np.max(rms)) if len(rms) else 0.0
    rms_thr = rms_max * RMS_REL_THRESHOLD if rms_max > 0 else 0.0
    mask_rms = rms > rms_thr

    L = min(len(f0), len(rms))
    f0 = f0[:L]
    per = per[:L]
    mask = (mask_per[:L]) & (mask_rms[:L])

    f0_masked = f0.copy()
    f0_masked[~mask] = np.nan

    # median í•„í„°
    f0_masked = _median_filter_crepe(f0_masked, MEDIAN_FILTER_WIN)

    # ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
    f0_masked = _remove_short_segments(f0_masked, sr, hop_length, MIN_SEG_DURATION_S)

    times = librosa.frames_to_time(np.arange(L), sr=sr, hop_length=hop_length)
    return f0_masked, times, per, rms[:L]

# =========================
# CREPE ì˜ˆì¸¡ (2íŒ¨ìŠ¤ ê²°í•©)
# =========================
def _predict_crepe_with_masks(y, sr, hop_length, device, two_pass=True):
    """
    1íŒ¨ìŠ¤: 80â€“1200 Hz (ì¼ë°˜, ìƒí•œ ìƒí–¥)
    2íŒ¨ìŠ¤(ì„ íƒ): 600â€“1800 Hz (ê³ ìŒ êµ¬ì¡°), ì¡°ê±´ ì¶©ì¡± í”„ë ˆì„ë§Œ êµì²´
    """
    f0_1, times, per_1, rms = _predict_crepe_once(
        y, sr, hop_length, FMIN_BASE, FMAX_BASE, device
    )
    if not two_pass:
        return f0_1, times, per_1, rms

    # ê³ ìŒ êµ¬ì¡° íŒ¨ìŠ¤
    f0_2, _, per_2, _ = _predict_crepe_once(
        y, sr, hop_length, FMIN_HIGH, FMAX_HIGH, device
    )

    # êµì²´ ì¡°ê±´
    hi_gate_per = 0.60
    rms_max = float(np.max(rms)) if len(rms) else 0.0
    hi_gate_rms = (rms_max * RMS_REL_THRESHOLD) * 1.2

    need_hi = (
        (np.isnan(f0_1) | (f0_1 > (0.95 * FMAX_BASE)))
        & (~np.isnan(f0_2))
        & (per_2 > hi_gate_per)
        & (rms > hi_gate_rms)
    )

    f0 = f0_1.copy()
    f0[need_hi] = f0_2[need_hi]

    # ë§ˆì§€ë§‰ ì•ˆì „ median í•œ ë²ˆ(ì‘ì€ ìœˆë„ìš°ë¡œ ê³¼ë„ í‰íƒ„í™” ë°©ì§€)
    f0 = _median_filter_crepe(f0, 3)
    per = per_1  # ëŒ€í‘œ periodicityëŠ” 1íŒ¨ìŠ¤ë¥¼ ì‚¬ìš©
    return f0, times, per, rms

# =========================
# HYBRID: pYIN + CREPE ìœµí•©/ë³´ì •
# =========================
def _adaptive_hybrid_fuse(f0_pyin, f0_crepe, per_crepe, rms, widen_pct: int = 15):
    """
    1) pYIN ê²°ê³¼ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¼ë˜,
       - ìƒ/í•˜ìœ„ widen_pct% + NaNì€ CREPEë¡œ êµì²´
       - pYIN ìµœê³ ìŒì´ ë‚®ê²Œ ëˆŒë¦° ê²½ìš°(ìƒë‹¨ 90% ë¯¸ë§Œ) CREPE êµì²´ í­ì„ ìë™ í™•ëŒ€
    2) ê²¹ì¹˜ëŠ” í”„ë ˆì„ì€ ê°€ì¤‘ ìœµí•© (ê³ ìŒ/ì‹ ë¢° ë†’ì„ìˆ˜ë¡ CREPE ê°€ì¤‘â†‘)
    3) ì˜¥íƒ€ë¸Œ ê²€ì‚°ìœ¼ë¡œ ìµœì¢… ë³´ì •
    """
    L = min(len(f0_pyin), len(f0_crepe))
    l = f0_pyin[:L]
    c = f0_crepe[:L]
    per = per_crepe[:L]
    rms = rms[:L]

    out = l.copy()

    # í¼ì„¼íƒ€ì¼ ê²½ê³„
    valid_l = ~np.isnan(l)
    if valid_l.any():
        lo, hi = np.percentile(l[valid_l], [widen_pct, 100 - widen_pct])
    else:
        lo, hi = -np.inf, np.inf

    # ê¸°ë³¸ êµì²´ ë§ˆìŠ¤í¬
    mask_ext = (l <= lo) | (l >= hi) | np.isnan(l)

    # ìƒë‹¨ ëˆŒë¦¼ ê°ì§€(í•˜ë“œ ê°€ë“œ): pYIN ìµœê³ ê°€ CREPE ìµœê³ ë³´ë‹¤ 3ì„¸ë¯¸í†¤ ì´ìƒ ë‚®ìœ¼ë©´ êµì²´ í­ í™•ëŒ€
    try:
        l_max = np.nanmax(librosa.hz_to_midi(l))
        c_max = np.nanmax(librosa.hz_to_midi(c))
        if np.isfinite(l_max) and np.isfinite(c_max) and (c_max - l_max) >= 3.0:
            # ëˆŒë¦¼ ì‹¬í•¨ â†’ CREPEì™€ ê²¹ì¹˜ëŠ” êµ¬ê°„ë„ êµì²´ í—ˆìš©
            mask_ext = mask_ext | ((~np.isnan(c)) & (per > 0.5))
    except Exception:
        pass

    # êµì²´
    out[mask_ext & (~np.isnan(c))] = c[mask_ext & (~np.isnan(c))]

    # ê²¹ì¹˜ëŠ” í”„ë ˆì„ ê°€ì¤‘ ìœµí•© (CREPE ê°€ì¤‘ 0.7~0.9; RMS/periodicityì— ë¹„ë¡€)
    both = (~np.isnan(l)) & (~np.isnan(c))
    if both.any():
        # normalize weights from periodicity + rms
        per_n = (per - np.nanmin(per[both])) / (np.nanmax(per[both]) - np.nanmin(per[both]) + 1e-8)
        rms_n = (rms - np.nanmin(rms[both])) / (np.nanmax(rms[both]) - np.nanmin(rms[both]) + 1e-8)
        w_crepe = 0.7 + 0.2 * (0.5 * per_n + 0.5 * rms_n)  # 0.7~0.9
        w_pyin  = 1.0 - w_crepe
        mix = w_crepe * c[both] + w_pyin * l[both]
        out[both] = mix

    # ì˜¥íƒ€ë¸Œ ê²€ì‚°
    out = _fix_octave_jump(out, strength=0.6)
    return out

def _hybrid_replace_extremes_with_crepe(y, sr, hop_length, f0_librosa):
    """
    (ë ˆê±°ì‹œ) ìƒ/í•˜ìœ„ 5% + NaNì„ CREPE(2íŒ¨ìŠ¤ ì•ˆì •í™”)ë¡œ ë³´ì •
    â†’ ë³¸ íŒŒì¼ì—ì„œëŠ” _adaptive_hybrid_fuse ìª½ì´ ë” ì •ë°€í•˜ì—¬, hybrid ì—”ì§„ì—ì„œ ê·¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©.
    """
    valid = ~np.isnan(f0_librosa)
    if np.sum(valid) == 0:
        print("[í•˜ì´ë¸Œë¦¬ë“œ] ìœ íš¨í•œ librosa í”¼ì¹˜ê°€ ì—†ì–´ ë³´ì • ìƒëµ", flush=True)
        return f0_librosa

    lo, hi = np.percentile(f0_librosa[valid], [5, 95])
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[í•˜ì´ë¸Œë¦¬ë“œ] CREPE ì¬ë¶„ì„(2íŒ¨ìŠ¤) device={device}", flush=True)
    f0_crepe, _times, _per, _rms = _predict_crepe_with_masks(y, sr, hop_length, device, two_pass=True)

    L = min(len(f0_librosa), len(f0_crepe))
    f0_l = f0_librosa[:L]
    f0_c = f0_crepe[:L]

    mask_ext = (f0_l <= lo) | (f0_l >= hi) | np.isnan(f0_l)
    out = f0_l.copy()
    out[mask_ext] = f0_c[mask_ext]
    return out

# =========================
# ë©”ì¸ ì—”íŠ¸ë¦¬
# =========================
def analyze_audio_summary(source: str, engine="pyin", target_sr=22050,
                          hop_length=HOP_LENGTH_DEFAULT, plot=False):
    global MEDIAN_FILTER_WIN, FMAX_BASE, FMAX_HIGH
    # 1) ì†ŒìŠ¤ ì •ê·œí™”
    if source.startswith("http"):
        source = download_youtube_audio(source)

    # 2) ë³´ì»¬ ë¶„ë¦¬ (Demucs)
    #    - ë‚´ë¶€ êµ¬í˜„ì—ì„œ htdemucs / --two-stems=vocals ì‚¬ìš© ê°€ì •
    source = separate_vocals_demucs(source)

    # 3) ë¡œë“œ
    y, sr = load_audio(source, target_sr=target_sr, mono=True)

    # 4) í”¼ì¹˜ ì¶”ì •
    if engine in ["pyin", "yin"]:
        f0_hz, times = estimate_pitch_librosa(y, sr, hop_length=hop_length, use_pyin=(engine=="pyin"))

    elif engine == "torchcrepe":
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(
            f"[CREPE] device={device} "
            f"base=({FMIN_BASE}-{FMAX_BASE})Hz hi=({FMIN_HIGH}-{FMAX_HIGH})Hz "
            f"voicing_th={VOICING_THRESHOLD} median={MEDIAN_FILTER_WIN}",
            flush=True
        )
        f0_hz, times, per, rms = _predict_crepe_with_masks(y, sr, hop_length, device, two_pass=True)

        # ğŸ” í‡´í–‰ ê°ì§€ ê°€ë“œ: ë²”ìœ„ê°€ 0.5 semitone ì´í•˜ì´ë©´ ì¬ì‹œë„(í•„í„° í•´ì œ + fmax í™•ì¥)
        voiced = f0_hz[~np.isnan(f0_hz)]
        if voiced.size > 8:
            midi = librosa.hz_to_midi(voiced)
            if (np.nanmax(midi) - np.nanmin(midi)) < 0.5:
                print("[ê²½ê³ ] f0 ë²”ìœ„ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ í˜‘ì†Œ. í•„í„° í•´ì œ + ìƒí•œ í™•ì¥ ì¬ì‹œë„.", flush=True)
                old_win, old_fmax_base, old_fmax_high = MEDIAN_FILTER_WIN, FMAX_BASE, FMAX_HIGH
                MEDIAN_FILTER_WIN = None
                FMAX_BASE, FMAX_HIGH = 1400.0, 2000.0
                f0_retry, _times2, _per2, _rms2 = _predict_crepe_with_masks(y, sr, hop_length, device, two_pass=True)
                MEDIAN_FILTER_WIN = old_win
                FMAX_BASE, FMAX_HIGH = old_fmax_base, old_fmax_high
                f0_hz = f0_retry

        # ì˜¥íƒ€ë¸Œ ê²€ì‚°(ìµœì¢…)
        f0_hz = _fix_octave_jump(f0_hz, strength=0.6)

    elif engine == "hybrid":
        # 1) pYIN ê¸°ë³¸ ì¶”ì •
        f0_l, times = estimate_pitch_librosa(y, sr, hop_length=hop_length, use_pyin=True)
        # 2) CREPE(2íŒ¨ìŠ¤, ê³ ìŒ ëŒ€ì‘) ì¶”ì •
        device = "cuda" if torch.cuda.is_available() else "cpu"
        f0_c, _times2, per, rms = _predict_crepe_with_masks(y, sr, hop_length, device, two_pass=True)
        # 3) ì ì‘í˜• ìœµí•©/ë³´ì • + ì˜¥íƒ€ë¸Œ ê²€ì‚°
        f0_hz = _adaptive_hybrid_fuse(f0_l, f0_c, per, rms, widen_pct=15)

    else:
        raise ValueError("engineì€ pyin, yin, torchcrepe, hybrid ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    # 5) ë””ë²„ê·¸: ì›ì‹œ ìµœì†Ÿê°’/ìµœëŒ“ê°’
    valid_f0 = f0_hz[~np.isnan(f0_hz)]
    if len(valid_f0) > 0:
        raw_max_hz = float(np.max(valid_f0))
        raw_min_hz = float(np.min(valid_f0))
        print(f"[ë””ë²„ê·¸] ìµœì € Hz: {raw_min_hz:.2f}, ìµœê³  Hz: {raw_max_hz:.2f}", flush=True)
        max_midi = float(librosa.hz_to_midi(raw_max_hz))
        min_midi = float(librosa.hz_to_midi(raw_min_hz))
        print(
            f"[ë””ë²„ê·¸] ìµœì €ìŒ: {librosa.midi_to_note(min_midi, octave=True)} (MIDI {min_midi:.2f}), "
            f"ìµœê³ ìŒ: {librosa.midi_to_note(max_midi, octave=True)} (MIDI {max_midi:.2f})",
            flush=True
        )

    # 6) ì—ë„ˆì§€Â·ìš”ì•½ì¹˜
    rms, _ = compute_rms(y, sr, hop_length=hop_length)

    # âœ… summarize_pitchëŠ” NaNì„ ë¬´ì„±ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •
    p_sum = summarize_pitch(f0_hz, sr, hop_length)
    e_sum = summarize_energy(rms)

    print("[ì™„ë£Œ] ë¶„ì„ ì¢…ë£Œ", flush=True)

    # 7) ì‹œê°í™”
    if plot:
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(figsize=(10, 4))
        S = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
        lrdisplay.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='hz', ax=ax)
        ax.set_title('Spectrogram + Pitch Track')
        ax.plot(times, f0_hz, label='f0 (stabilized)', linewidth=2)
        ax.legend()
        plt.savefig("pitch_track.png")
        print("[ì‹œê°í™”] pitch_track.png ì €ì¥ ì™„ë£Œ", flush=True)

    # 8) ê²°ê³¼
    return {
        "engine": engine,
        "sr": int(sr),
        "duration_s": float(len(y) / sr),
        "frames": int(p_sum.frames),
        "voiced_ratio": float(p_sum.voiced_ratio),
        "midi_min": float(p_sum.midi_min),
        "midi_min_note": midi_to_note(p_sum.midi_min),
        "midi_median": float(p_sum.midi_median),
        "midi_median_note": midi_to_note(p_sum.midi_median),
        "midi_max": float(p_sum.midi_max),
        "midi_max_note": midi_to_note(p_sum.midi_max),
        "rms_mean": float(e_sum.rms_mean),
        "rms_std": float(e_sum.rms_std),
    }
